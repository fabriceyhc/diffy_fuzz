{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_textbook_fn(x):\n",
    "    return (0.2) + \\\n",
    "           (0.4 * x**2) + \\\n",
    "           (0.3 * np.sin(15 * x)) + \\\n",
    "           (0.05 * np.cos(50 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "    print(y)\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if y > 100:\n",
    "        return \"dl_textbook_fn returned a value more than 100!\"\n",
    "    \n",
    "    if y < 100:\n",
    "        return \"dl_textbook_fn returned a value less than 100!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fn(x):\n",
    "    return 20*x + 3*x**2 + 0.1*x**3\n",
    "\n",
    "def program_4_sym(x: float):\n",
    "    y:float = 20*x + 3*x**2 + 0.1*x**3\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if y == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "        \n",
    "    return r\n",
    "\n",
    "def program_4(x: float):\n",
    "    y:float = poly_fn(x)\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if round(y, 2) == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "76qmzmqjJAiL"
   },
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "\n",
    "    if y > 0:\n",
    "        print(\"dl_textbook_fn returned a positive value!\")\n",
    "    elif y < 0:\n",
    "        print(\"dl_textbook_fn returned a negative value!\")\n",
    "    elif y == 0:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.505904007381"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_textbook_fn(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[5, 0], [5, 1], [8, 0], [8, 1], [11, 0], [11, 1]]\n"
     ]
    }
   ],
   "source": [
    "phase1_start = time.time()\n",
    "\n",
    "config = get_subject_programs_config()[6]\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')\n",
    "    \n",
    "phase1_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase2_start = time.time()\n",
    "\n",
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)\n",
    "\n",
    "phase2_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '==', 'target': '100'},\n",
       "   {'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'}],\n",
       "  'target_fn': <function __main__.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ec4955808c4461b6325b4ce530ce08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcf506a4f8d4aeab2e784dcad4985a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.003785531735047698}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "phase3_start = time.time()\n",
    "\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    input_range = (-50, 50), \n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 1000, \n",
    "    batch_size=4, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=torch.cuda.device_count()\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "phase3_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: == target: 100.0\n",
      "x_adv: [-15.8035  15.8948 -15.8034  15.8946  15.8946]\n",
      "error You found a hard-to-reach bug!\n",
      "dl_textbook_fn(x) > 100! 101.10785143245286\n",
      "error You found a hard-to-reach bug!\n",
      "dl_textbook_fn(x) > 100! 101.10516986384519\n",
      "dl_textbook_fn(x) > 100! 101.10516986384519\n",
      "op: > target: 100.0\n",
      "x_adv: [ 50. -50. -50. -50. -50.]\n",
      "dl_textbook_fn(x) > 100! 1000.4615131407621\n",
      "dl_textbook_fn(x) > 100! 1000.0144693705869\n",
      "dl_textbook_fn(x) > 100! 1000.0144693705869\n",
      "dl_textbook_fn(x) > 100! 1000.0144693705869\n",
      "dl_textbook_fn(x) > 100! 1000.0144693705869\n",
      "op: < target: 100.0\n",
      "x_adv: [0.6904 0.6905 0.6905 0.6905 0.6905]\n",
      "dl_textbook_fn(x) < 100! 0.09988268506656901\n",
      "dl_textbook_fn(x) < 100! 0.09986576428519557\n",
      "dl_textbook_fn(x) < 100! 0.09986576428519557\n",
      "dl_textbook_fn(x) < 100! 0.09978975037234515\n",
      "dl_textbook_fn(x) < 100! 0.0997391922631714\n"
     ]
    }
   ],
   "source": [
    "phase4_start = time.time()\n",
    "\n",
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)\n",
    "    \n",
    "phase4_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 100.0\n",
      "Total Runtime: 20.353925704956055\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "\n",
    "total_time = phase1_end - phase1_start + \\\n",
    "             phase2_end - phase2_start + \\\n",
    "             phase3_end - phase3_start + \\\n",
    "             phase4_end - phase4_start\n",
    "\n",
    "print(\"Total Runtime:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
