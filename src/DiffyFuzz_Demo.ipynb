{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_textbook_fn(x):\n",
    "    return (0.2) + \\\n",
    "           (0.4 * x**2) + \\\n",
    "           (0.3 * np.sin(15 * x)) + \\\n",
    "           (0.05 * np.cos(50 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "    print(y)\n",
    "\n",
    "    if y > 100:\n",
    "        return \"dl_textbook_fn returned a positive value!\"\n",
    "    elif y < 100:\n",
    "        return \"dl_textbook_fn returned a negative value!\"\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[5, 0], [5, 1], [7, 0], [7, 1], [10, 0], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "phase1_start = time.time()\n",
    "\n",
    "config = get_subject_programs_config()[6]\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')\n",
    "    \n",
    "phase1_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase2_start = time.time()\n",
    "\n",
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)\n",
    "\n",
    "phase2_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'},\n",
       "   {'operator': '==', 'target': '100'}],\n",
       "  'target_fn': <function __main__.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e506fc4b6043cab498815a7e533761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6636b31466aa4f4ea2f3a448973e3194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0011370346182957292}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "phase3_start = time.time()\n",
    "\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 2000, \n",
    "    max_dataset_size = 2000, \n",
    "    batch_size=10, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./logs/\", name=fn.__name__)\n",
    "escb = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=2, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=torch.cuda.device_count(),\n",
    "    logger=tb_logger,\n",
    "    callbacks=[escb]\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "phase3_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA27UlEQVR4nO3dd3RU1drH8e+TDiSEACF0CEV6NRTpXYoKKFywIFVULOjVq9zXgoVrbxdUFDUKVxBsFAUFRKrU0HsvSQgQQgKBkJBk9vtHDq4RAwmknJnJ81lrFpN92m8PkGdO20eMMSillCravOwOoJRSyn5aDJRSSmkxUEoppcVAKaUUWgyUUkqhxUAppRRaDJRSSqHFQLkxEflKRCaISCcRibE5S3URMSLiUwDrNiJS6zqXaSsi+0XkvIj0y+9MyvNoMVBFhogcEZFurrauAvIK8KExJtAYM8fuMMr1aTFQyjNVA3baHUK5Dy0Gym2ISDMR2SQiySIyCwi4jmX/B1QFfrIOnTxjtbcWkdUikiQiW0Wkk9XeRkROi0gV6+cmIpIoInWvti7LCBE5LiJxIvK00/b9ReQDa9px672/0/QHROSAiJwRkXkiUvEq/WgnItGXc15lnoNADad8/iKyTEReFZE/rM9vkYiUze3np4oAY4y+9OXyL8APOAo8CfgCA4B0YALQCYjJxTqOAN2cfq4EJAC9yfpi1N36OdSa/h/gd6AYsB149Brrqg4Y4BugBNAIiL88D1mHbdYC5YBQYDXwqjWtC3AaaA74A5OAFU7rNkAtoCcQDbS8gb4uAw4CN1n9WQa8Yfffq75c56V7BspdtCarCHxgjEk3xnwPbMjjOu8DFhhjFhhjHMaYxUAUWcUB4CUgGFgPxAIf5WKdLxtjLhhjtgNfAndb7fcCrxhjThlj4oGXgSFO0yKNMZuMMWnAv4FbRKS603oHAp8CvYwx62+su3xpjNlnjLkIfAs0vcH1KA+kxUC5i4pArDHGeZjdo3lcZzVgoHWIKElEkoB2QAUAY0w68BXQEHj3im1fTfQV+S4f7ql4Rd6rTjPGnCdrD6WS0/xPAN8aY3bkpmNXccLpfQoQmId1KQ+jxUC5izigkoiIU1vV61zHlb/Mo4H/GWNKOb1KGGPeABCRSsB4sr7hv+t8jD+bdV1W5Yp8x633x8kqPjlOE5ESQBmy9kYuGwj0E5GxOfRRqRuixUC5izVABvC4iPiKyJ1Ay+tcx0myTqxe9jVwu4jcKiLeIhJg3bNQ2So6XwFfACPJKkavXmNdl70gIsVFpAEwHJhltX8DPC8iodaJ2xet7V+eNlxEmloF5zVgnTHmiNN6jwNdgbEi8vB19lupHGkxUG7BGHMJuBMYBpwBBgE/XudqXifrF3KSiDxtjIkG+gL/R9bJ3mjgX2T9v3icrJO9L1iHh4aT9Qu7fXbrctrGcuAAsAR4xxizyGqfQNb5iG1knYzeZLVhjPkNeAH4gayiUxMYnM1ncIysgjBOREZdZ9+VuibJ3WFQpZRSnkz3DJRSSpHv46goZRcRqQrsusrk+tZhFo9gHa76Jbtpxhi9SkhdNz1MpJRSyn33DMqWLWuqV69udwyllHIrGzduPG2MCb2y3W2LQfXq1YmKirI7hlJKuRURyfZmTT2BrJRSSouBUkopLQZKKaXQYqCUUgotBkoppdBioJRSCi0GSiml0GKglFJuY2t0Eh/+vp/k1PR8X3eRKgYOh+H/Zm9n8rKDdkdRSqnrNm3NUT5ZfghvL8l55utUpIqBl5dwPOkiU1cfIdOhYzIppdzHudR05m8/zu1NKlLcL/8HjyhSxQDgn2XX8+rF/7Bi7ym7oyilVK79tPU4j5pveNxndoGsP8diICJVRGSpiOwSkZ2Xn8EqIi+JSKyIbLFevZ2W+beIHBCRvSJyq1N7T6vtgIiMc2oPF5F1VvssEfHL745eVr+cP929N7Jh1a8FtQmllMp3s9Yf4+aAE5Q3BfNFNjd7BhnAU8aY+kBr4BERqW9Ne98Y09R6LQCwpg0GGgA9gY+t58t6Ax8BvYD6wN1O63nTWlctIJGsZ84WCJ+md5PqHUi9Y98Qn5xWUJtRSql8s+v4ObbFnmNP50+R2z4okG3kWAyMMXHGmE3W+2RgN1DpGov0BWYaY9KMMYfJeh5sS+t1wBhzyHqe7Uygr/Xg8S7A99byU4F+N9ifnPkHktpgMD291vPrms0FthmllMovP6w/RBWfRPo3qwTeBTPY9HWdMxCR6kAzYJ3V9KiIbBORSBEJsdoqkfVg8ctirLartZcBkowxGVe0Z7f90SISJSJR8fHx1xP9L0p1HIO3OHBERaIP91FKubLU9ExStnzHMp/HKXVub4FtJ9fFQEQCgR+AJ4wx54DJQE2gKRAHvFsQAZ0ZY6YYYyKMMRGhoX97NkPulanJ7jpj+PV8LdYdPpN/AZVSKp8t3BHHPY6fSQsOh7CGBbadXBUDEfElqxBMN8b8CGCMOWmMyTTGOIDPyDoMBBALVHFavLLVdrX2BKCUiPhc0V6gag54lZ1+TZi+zmMei6uU8kCbV/1CI68jBLR7FCT/7y+4LDdXEwnwBbDbGPOeU3sFp9n6Azus9/OAwSLiLyLhQG1gPbABqG1dOeRH1knmeSbrOM1SYIC1/FBgbt66lbMAX29GNvQhbFckp8/riWSllOs5GH+eVqdmkeoTjFeTQQW6rdzsGbQFhgBdrriM9C0R2S4i24DOwJMAxpidwLfALuBX4BFrDyIDeBRYSNZJ6G+teQGeBf4pIgfIOofwRf518eruKbWT572nsfx3vcxUKeV65qzaRlevzWQ2Hwp+xQt0W+KuJ1AjIiJMnp+BnHqOlDfrsNKrBd2fm4tXAdzirZRSNyI1PZPWry+hT9UM/jOwJZQomy/rFZGNxpiIK9uL3B3IfxFQkhPhd9I5YxVrt++2O41SSv3p1+1xJKWk07td/hWCaynaxQCofOvj+Ekm8cs+sTuKUkr96czSSXxb4i1uqRxQKNsr8sXAL6wO+0u1J+H0KU6cTbU7jlJKsS8uia5nf6RqCYNXQGChbLPIFwMA//tm8kr6EGZtiM55ZqWUKmCbFs+gmtcpSnR8rNC2qcUAqFo2kA43hbJq3VoyMh12x1FKFWGp6ZnUPPQ/zviEEdS0f6FtV4uB5amKO/gu/VGi1iy1O4pSqghbtfJ3WrCL5CYjCmwcouxoMbA0aN+fFALIWDPZ7ihKqSLsq12ZTPEbStWuDxbqdrUYWHxKhLCvfB9anF9GbIwOUaGUKny7486xKiYTr/ZPIMVDcl4gH2kxcFKx++P4SzoHF35sdxSlVBG0Z8FH9Pddw4CbKxf6trUYOClXsym7AppTJXoel9Iz7Y6jlCpCLlw4T4djHzMyeCOlihfYwx6vSovBFc52e4s7Ul9m8W59RrJSqvDs+PULysg5fNs+Ysv2tRhcoWXzCIJDyjB97RG7oyiligpjCNsVyUGv6tzUqnfO8xcALQZX8PYSHqmfxnMxDxK9e13OCyilVB4d3vAL1TOPEFd3GOJlz69lLQbZ6N6qGTUkjtNLJtkdRSlVBPy++wRrTQMa9RplWwYtBtkoW648G0v1oN7pX0k9e+PPWlZKqZycvZjOOwcq8kPDyQQHBdmWQ4vBVQS2G0MA6Rz49SO7oyilPNiqxbPxSj/P0DbVbc2hxeAqmkS0YbN3Q8L2TofMDLvjKKU8kCMlkS6bHuODkO9oWCnY1ixaDK5CRDje+HHeSL2TPSfO2h1HKeWBDi36hGKk4tvKvnMFl2kxuIY23frzk1cnZkTF2R1FKeVpMjMotT2SjTSgTbuudqfRYnAtISX8uKt+MEGbPiEldqfdcZRSHiQ+6gfKZp4ipu5w/Hzs/1VsfwIXNziiPI8xk5hf3rM7ilLKgxze+BvHTDla97zH7iiAFoMcNa4dzoqAzlSJ+QmTkmh3HKWUB7h4KZNRpwYwsdbnhJUqYXccQItBjkQEr1YPUow0jvz2qd1xlFIeYH7UPs6lZvCPdo3sjvInLQa50L5DZzZSn8BtX4JDRzNVSt04czaGPos68VDpjbSoXrjPLLgWLQa54O/jTWyd+9l7qQwxsTF2x1FKubG43z7Cz6RRv2U3RMTuOH/SYpBLLXsPZ1jG83y19YLdUZRS7upSCsE7v2aptKBbm5Z2p/kLLQa5VD44gJ4Ny7MsaisXE6LtjqOUckPn1n9NCcc5YusMp7hf4T3sPje0GFyHES3KMcc8QfTcV+2OopRyN8ZwafVktjuq07HbHXan+RstBtehWa1KrPVvS5VjczEXk+yOo5RyI6kZDkakPsXcSk9TPTTQ7jh/o8XgOogIpuVoipHKkd8+szuOUsqNzN0Sy7aUELp07WV3lGzlWAxEpIqILBWRXSKyU0TGWu2lRWSxiOy3/gyx2kVEJorIARHZJiLNndY11Jp/v4gMdWq/WUS2W8tMFFc6xX6F9h27s4U6lNgaCQ6H3XGUUm7AnNpNtYUj6Bx6nltqlrE7TrZys2eQATxljKkPtAYeEZH6wDhgiTGmNrDE+hmgF1Dbeo0GJkNW8QDGA62AlsD4ywXEmucBp+V65r1rBSPA15vYm4ZQOv0EMbvX2h1HKeUGTiz6L03Tt9D/lnoudTmpsxyLgTEmzhizyXqfDOwGKgF9ganWbFOBftb7vsA0k2UtUEpEKgC3AouNMWeMMYnAYqCnNa2kMWatMcYA05zW5ZJa9B5G14yJfLq/pN1RlFKuLuUMpQ/+yC9eHbm1ZQO701zVdZ0zEJHqQDNgHRBmjLk8tvMJIMx6XwlwvvYyxmq7VntMNu3ZbX+0iESJSFR8vH2PoyxXKoiWTRvz3cZoEs+n2pZDKeX6EpZ/ir9J40KzUfj7eNsd56pyXQxEJBD4AXjCGHPOeZr1jd7kc7a/McZMMcZEGGMiQkNDC3pz1zSqXTiTeJtj34y1NYdSyoVlpuOz8XP+cDSiV5cudqe5plwVAxHxJasQTDfG/Gg1n7QO8WD9ecpqjwWqOC1e2Wq7VnvlbNpdWp0KJSkWVIqasXNJu5BkdxyllAs6k3yBL9O6sKvWSMoE+tsd55pyczWRAF8Au40xzoP6zwMuXxE0FJjr1H6/dVVRa+CsdThpIdBDREKsE8c9gIXWtHMi0tra1v1O63JpJdqNIZCL7PpFRzNVSv3djE3xfJDej063DrA7So5ys2fQFhgCdBGRLdarN/AG0F1E9gPdrJ8BFgCHgAPAZ8AYAGPMGeBVYIP1esVqw5rnc2uZg8Av+dC3Atf0lq7s9r6JsrumYnQ0U6WUk0sxW4j9YwadapemdliQ3XFylOPgGMaYVcDVroX624M7rfMHj1xlXZFAZDbtUUDDnLK4GhHhbKMR1Nsyjp2r5tKgw512R1JKuYhT819jXMZKtrUemvPMLkDvQM6jZr2G8Z7XMD7ep5eZKqWymMSjVIhbzK/+t9KufjW74+SKFoM88vcvhk/bR5l/II39J5PtjqOUcgFxiydhDBRr+7DL3mR2JS0G+eDeVlXp67uevXPeyHlmpZRnSztPqT0z+N2rNT3aRNidJte0GOSDMoH+3F92H12Of0ZC/Am74yilbBRzZC8nMkqS0HAkAb6ue5PZlbQY5JPQHk9RXNLY8/MHdkdRStloyh5/emW+S9cet9kd5bpoMcgnVetFsK1YS+oc/YbUi/poTKWKosTY/fwUtZ87mlamXFCA3XGuixaDfOTV9jHKksS2BVPsjqKUssG5bx9mhrzIgx3C7Y5y3bQY5KMGbW5jmW8Hfj5wCYejwIdqUkq5kJTobVQ7u4HdZXtQK8z9LjXXYpCPxMuLpN6fMC2xIUv2nMp5AaWUx4he8A4XjR+1ej1qd5QbosUgn93WuAK1S8GOX7+wO4pSqpCknTlGjbj5rAjsSePa7neICLQY5Dsfby8mVNvCk+feZNf6JXbHUUoVgl2/TUeMg1Jd/2l3lBumxaAANL79UZIIJG3p23ZHUUoVsEyH4anoW3i41GRaNmtqd5wbpsWgABQLDGZP1XtodnENh3dtsDuOUqoA/bbjGIfiL9C3awe3GXoiO1oMCkjdO57mgvHnzMI37Y6ilCog5tIFms/pymMlV9CrYQW74+SJFoMCUqpsGNvC+pOaGEdMwrmcF1BKuZ3Dv00h1BFPo2at8PZy370C0GJQoKoNfodhmc8xZdUxu6MopfJbZgZBGyezlTp06HqH3WnyTItBAapYOoi7mldmyYZtxJ88bnccpVQ+il41ndDMkxxv+BABfjk+J8zlaTEoYGNahvCb91j2z3nd7ihKqfxiDKyeyAFTmbZ97rU7Tb7QYlDAqlapwp6SbWl0/DuSEuLtjqOUygeHE1IYlvwwaxuOp2Qxf7vj5AstBoWg9K3PEiQX2TH3XbujKKXywZQVh4j2qkSPnu5/ruAyLQaFoFrDW9hRrCX1jk3nXPJZu+MopfLgzJ6VdN3yBCMb+bndMNXXosWgkBTr+i9KmWSWL5prdxSlVB4kzn+FZrKPuzs2tjtKvtJiUEhqRvTg6UpfM35XBVIuZdgdRyl1AxL3rKBm8npWh91L1fKhdsfJV1oMCtG9Pdpw5sIlvluzz+4oSqkbkLjgFU6bkjTq/5TdUfKdFoNCFFG9NP8tM5sOSweQdumS3XGUUtchac9yapzbwB9h91G9gmftFYAWg0J3U7MOhBPL+gVT7Y6ilLoOX+7z572MATTq577DVF+LFoNCVrfzPcR4V6b81g+5lK7nDpRyBwnn05iyIYmjDR+lRkXP2ysALQaFTrx9ONdiLLXNEdbM170DpdzB4a8fpUXmZh7rUsvuKAVGi4EN6nUfTqx3ZUpt/ZTU9Ey74yilriF5zzIiTnzLHZWSqVUuyO44BSbHYiAikSJySkR2OLW9JCKxIrLFevV2mvZvETkgIntF5Fan9p5W2wERGefUHi4i66z2WSLil58ddEXi7cvpnh8z7OKTTF+nI5oq5crOLHiFU6YUTfo9YXeUApWbPYOvgJ7ZtL9vjGlqvRYAiEh9YDDQwFrmYxHxFhFv4COgF1AfuNuaF+BNa121gERgZF465C6atOhIvZrhTF66nwupemWRUq4oec9Sqp3byPLQe6ldqZzdcQpUjsXAGLMCOJPL9fUFZhpj0owxh4EDQEvrdcAYc8gYcwmYCfSVrGfEdQG+t5afCvS7vi64r2fbhfBF+rP8Mfczu6MopbKRtOBVTppSNO431u4oBS4v5wweFZFt1mGkEKutEhDtNE+M1Xa19jJAkjEm44r2bInIaBGJEpGo+Hj3HwG0SZ3alPF3UHv3h5xLSbU7jlLKydkLaXx5tjkLwh6iTuUwu+MUuBstBpOBmkBTIA4olOE4jTFTjDERxpiI0FAPuLzLywtHx3GEc5w/Zn9idxqllJMpqw4TmdaZVv0esTtKobihYmCMOWmMyTTGOIDPyDoMBBALVHGatbLVdrX2BKCUiPhc0V5kVG0ziGi/mtTfN5nE5BS74yilyLrb+OIfn9K3UVnqVyxpd5xCcUPFQEQqOP3YH7h8pdE8YLCI+ItIOFAbWA9sAGpbVw75kXWSeZ4xxgBLgQHW8kOBojWsp5cXXl3+j2pyglVzPrU7jVLKGM7+/CKjZTZju9S0O02hyfHBnSLyDdAJKCsiMcB4oJOINAUMcAR4EMAYs1NEvgV2ARnAI8aYTGs9jwILAW8g0hiz09rEs8BMEZkAbAa+yK/OuYtKre5i2tbDvL2vJq2SUz1qjHSl3E3CjsVUO7+F2RXG0r9CWbvjFBrJ+nLufiIiIkxUVJTdMfLN4dMX6Pbecu6/pRrjb29gdxyliiZjOPJ2ewIuxJL+yEaqlCttd6J8JyIbjTERV7brHcguIrxsCV6sdZjeG0ZwPEGfhqaUHU5u+ZXqKduJqjLMIwvBtWgxcCG9m1Wjhdce1v44ye4oShVJs7acZom5mZZ3PmF3lEKnxcCFhDbtQ3TxBrSOieToqdze56eUyg/7Tybz/r7SrG/1EeVKB9sdp9BpMXAlIgT2Gk9FSWDDj/+1O41SRYfDwdZv/0MFv1Qe6lh0riBypsXAxYQ07EF0YBPaxU3l4HH3v8taKXdwbNV0BiRMZvxNRwkp4fFjZWZLi4GrEaFk3zd4xTzAe0t1RFOlClxGGgHLJ7CXatzSf4zdaWyjxcAFBdduQ812A5i//QS7jp+zO45SHu3ggg8ol3mCw82epWTxonuPjxYDFzWqbTWeC/iOrd+/YXcUpTyW40Ii5TZPZJ1XUzr3GWx3HFtpMXBRwSUC6FYmgdsSItmye6/dcZTySL9uOcTqjLqkdHwRfx9vu+PYSouBCys/4G2KySVOzX0Rd71TXClXlZqeyX9WnuXDci/TsX0Xu+PYTouBCytWoS4Hq99Nt4sLWf3HUrvjKOVRNn77Bn5nD/Hv3nXx8hK749hOi4GLqzngVc57BeK/9CXSMx12x1HKIyQf2kDb/W/xdOgG2tQsOoPRXYsWAxfnE1iaw23f5vmUu5m5Xi81VSrPjOH07GdJMEHcdNeLdqdxGVoM3EDjroMJrt6UD37bz7mLl+yOo5Rbi9/8M+HJG1lZYQS1q131KbtFjhYDNyAivNC7Ni9ceo9N01+wO45S7suRScbCFzhiytPqH0/ZncalaDFwEw2rlKVmiA+toiM5dlgvNVXqRmw/dooFF+qyqc6TVCiCg9FdixYDN1Jh0HsIhpPf/8vuKEq5HWMML/1ymMkBo+h+50i747gcLQZupGyl2mwNH0mLC8vZvrJoPSpaqbza/NPH+EWv4plb6xAU4Gt3HJejxcDNNBn0IrEShvey/5Chl5oqlSspZ45TZ9MrPBb4OwNurmx3HJekxcDNBBQrwdEuHzH0wli+2RBtdxyl3MKhmc/ia9IJ7DNBbzC7Ci0GbuiWdt2oWaMG7y/czdmkJLvjKOXSTu35g4an5rG89AAaN/nbc+CVRYuBGxIRXuxTj0mZr3B02oN2x1HKdTkcXJjzFPEmmAaDJ9idxqVpMXBT9SuVIq18BI3P/ErMliV2x1HKJa0/nMDU5Basr/MMFcPK2R3HpWkxcGON736Z46YsZv7TkJlhdxylXEqmw/Dy/D0sDOxH5wEP2R3H5WkxcGNlQ0LY2ehZqqQfYv+C/9odRymXsmPWeOqe+JlxvepS3M/H7jguT4uBm+vYdyQbvJrA5q+5lK57B0oBJEfvov7ej+hV8hB3NKlodxy3oMXAzfn5epN2+0fclvIikauP2h1HKZdw/NsnSTW+VLrrdUT0UtLc0GLgAdo1a0T7elX4dMlOTh3TcYtU0Xbojx+ok7yW1ZVHUa92LbvjuA0tBh5i/O31+UwmcHH6feDItDuOUrbITL9EwJLnOEwl2tzzb7vjuJUci4GIRIrIKRHZ4dRWWkQWi8h+688Qq11EZKKIHBCRbSLS3GmZodb8+0VkqFP7zSKy3Vpmoug+3Q2pUro4p+sOoVraPvYtmGh3HKVs8fX6WF5IvYfj7V8jqEQJu+O4ldzsGXwF9LyibRywxBhTG1hi/QzQC6htvUYDkyGreADjgVZAS2D85QJizfOA03JXbkvlUucBD7PJuzEVot7i4pk4u+MoVahOnUvlnUX7SKtxK2269LU7jtvJsRgYY1YAZ65o7gtMtd5PBfo5tU8zWdYCpUSkAnArsNgYc8YYkwgsBnpa00oaY9YaYwwwzWld6jr5+/rgddu7+Js0Ds540u44ShWq/ZGjGO74gVf6NtCTxjfgRs8ZhBljLn/1PAGEWe8rAc6jp8VYbddqj8mmPVsiMlpEokQkKj4+/gaje7amzVqyMvQeUk8dYm/MKbvjKFUotq/6mbZJP9G2WnFqhAbaHcct5fkEsvWN3uRDltxsa4oxJsIYExEaGloYm3RLze9/gwd9XmXcvP04HIXyV6OUbdJSUwhe8gzHJYwm97xqdxy3daPF4KR1iAfrz8tfQWOBKk7zVbbartVeOZt2lQchJQN57rYGxBw7wvKfv7Y7jlIFauuMF6lqYonv+DoBxYPsjuO2brQYzAMuXxE0FJjr1H6/dVVRa+CsdThpIdBDREKsE8c9gIXWtHMi0tq6iuh+p3WpPOjfrBLvh3xPq01PcTrmgN1xlCoQh6OjaXh0GuuDutKk0112x3Frubm09BtgDVBHRGJEZCTwBtBdRPYD3ayfARYAh4ADwGfAGABjzBngVWCD9XrFasOa53NrmYPAL/nTtaJNRKg64HUwEDPzCbvjKJXvHA7Dv36OZri8Svi9H9gdx+3lOHqTMebuq0zqms28BnjkKuuJBCKzaY8CGuaUQ12/qjXr8kf4A7Q98iHbfp9F4y6D7I6kVL6ZtXwTUUcTeWdgH0LL66Ms80rvQPZwEXc/z1GvKpRd+Tznk5PsjqNUvoiNOUavZXfwRvll3NX8qhcgquugxcDD+fsX4+Kt7xGVUZP/Ltxldxyl8swYw+EZT1CCi3S+4z69pyCfaDEoAuq26sHWVu/xWVQiqw+ctjuOUnmyav7XtEtZwu5aowir0cTuOB5Di0ER8XSPOnQonUjajPu4cC7R7jhK3ZBTJ2KoH/UcR3xq0HCw3lOQn7QYFBHF/Lz5d8dydMxcy85pT9gdR6nrZozhf3PmI8aB78DP8fL1tzuSR9FiUITUa9WDdWGDaXl6DjtXzbM7jlLX5adtcUw6Upm5nRZSqc7NdsfxOFoMipimQ9/hmFSk9JJ/kpKsh4uUe0iI2cfmORNpUjmY+zvWtzuOR9JiUMQUKxHI+Z4TCXOcZv30l+yOo1SOTMYlkqYN4UnHVN7vXR5vL716qCBoMSiC6rfqzsxab/HgkU6s3K+jvyrXtmvGs9S8tIeNTV6iRg19jGVB0WJQRN05eCRVy5XmhW/Xkph45eMqlHINcRvn0+BQJEtK9KFjv9F2x/FoWgyKqABfbz64qy5fXnqa3V8+TNZIIkq5jvSLyQT8PIYDVKHhiI/w0sNDBUqLQRHWoFoYZ6r1ps25X1k7f5rdcZT6i0krj/Nk2gMc7/4xYWVCcl5A5YkWgyKu6ZA3OORTkzobniM25qjdcZQCYOvuvXy49ABlmt5Oh7Yd7I5TJGgxKOK8ff0pNugLSpBK3P9GkZGRaXckVcSlHFxD3VntGBS0jZfu0MtIC4sWA0WF2s3Y2+ifOC6eZfKiLXbHUUXZxSRSZw7jlAlm4IC7CQrwtTtRkaHFQAHQ+M5x/NhoMu+tPMGKfXq5qbKBMcT9bxRBl+JZ3ugNmt9U3e5ERYoWA5XFy4vxfZvSomw6cd88yskEvTtZFa6EpR9S4fhivg4czj/63Wl3nCJHi4H6UzE/b97v5Msg8ytbv3iUjEyH3ZFUEZGansmcDQf5nRZ0H/kyfj76q6mw6Seu/qLSzX3YV2MYPVJ+Zv63n9kdRxURry3YzauJ3XEM/B+VSwfaHadI0mKg/uame94mJuAmOux5hXVbt9sdR3kyYzgy7WGOrZvLqHbhdGtQwe5ERZYWA/V3Pn6UHfo1AZJB4pxxnDyXanci5aFOL59C9UMz6Bpykmd61rU7TpGmxUBlK6BCHRJu/5KXM4YyduZmMh06XIXKX6kx2wha9jx/0ITOI1/T8wQ2009fXVXlm3vzVL82RB06ReTPS+2OozyISUvm7LR7OGuKY/p9qucJXIAWA3VNA26uzPflvqL3xlH8HqXnD1T+WPPjR4SmxbCq8Ru0a1rP7jgKLQYqF+oNeIGycp6Qn0awN+aU3XGUm1tzMIEh2xvxWuWP6Nd/sN1xlEWLgcqRf9XmXLztI5rJPg5/+QBnzqfZHUm5qVOHtvHm9PlUK1OCsUP+ocNSuxAtBipXSkUMJK75P+mZuYwFU54jXW9IU9cpNSWZi9PvY2LmBKbc21THHXIxWgxUrlW4/UX21RjK1PjaTPh5l91xlBsxDgc7PhlGlYxjnOrwGrXKl7I7krqCFgOVeyLcdP9EOrZtz9Q1R/hx1Va7Eyk3sXrq80Sc+4314WOI6DrA7jgqG3kqBiJyRES2i8gWEYmy2kqLyGIR2W/9GWK1i4hMFJEDIrJNRJo7rWeoNf9+ERmaty6pgjauV13+W+5n2izux9adO+yOo1zc6sXf0/boR2ws2Y1W90+wO466ivzYM+hsjGlqjImwfh4HLDHG1AaWWD8D9AJqW6/RwGTIKh7AeKAV0BIYf7mAKNfk4+1FlzsfIlBSKfHdYKJjY+2OpFzUpmOJPLDcj5mB99NwzDTESw9GuKqC+JvpC0y13k8F+jm1TzNZ1gKlRKQCcCuw2BhzxhiTCCwGehZALpWPgqo3JbnfV1TjOIlfDCAx6azdkZSLOX7sIE9NXUaZkkH0ePhd/ANK2B1JXUNei4EBFonIRhEZbbWFGWPirPcngDDrfSUg2mnZGKvtau3KxVVoeivHOrxPw8zd7J88iItpGXZHUi7iTOIZLnx1F5MyXyVy6M2ULuFndySVA588Lt/OGBMrIuWAxSKyx3miMcaISL4NamMVnNEAVatWza/Vqjyo2WUoW5OT+Gz9WdJnbGLKkAgdY6aIu3Axjf2TBxOReYQD3b+kVlhJuyOpXMjT/1pjTKz15ylgNlnH/E9ah3+w/rx8y2osUMVp8cpW29Xas9veFGNMhDEmIjQ0NC/RVT5q0ncsne8YxrK98bw/bRaZeg9CkXUpw8Hyj8fQ6tI69jd/njrt+tsdSeXSDRcDESkhIkGX3wM9gB3APODyFUFDgbnW+3nA/dZVRa2Bs9bhpIVADxEJsU4c97DalBu5p1VV3mkHTx99mNWTH8I4tCAUNQ6HYc5nr9I7+Xv2V7ubun2ftjuSug55OUwUBswWkcvrmWGM+VVENgDfishI4CjwD2v+BUBv4ACQAgwHMMacEZFXgQ3WfK8YY87kIZeyyYA+vdkYM5D2J2ax4ouStB/1Nta/D+XhjDH8Z8Fu5h6tTfhNo2gx9C27I6nrJMa45zj1ERERJioqyu4Y6grGkcnmD++j+ZkFrKz5FO2HvGh3JFUIfv5hGk9sCOa+NrUYf3t9/RLgwkRko9OtAH/SM30qX4mXN03HTGNrUEfaH3yXBb/MszuSKmBrZ7zKbdsf450qq3nxNi0E7kqLgcp3Xj6+1H90Fp+XHceY5V7M3hxjdyRVQDZ+/Tyt973DphId6PPAyzoKqRvTYqAKhK9/Me578BluqVGWT7+fz8Yl39kdSeUnY9g27WluPjCJdYFdafTED/j6BdidSuWBFgNVYAJ8vflsaASvF59JwxUPs3X5bLsjqXzyw7J1hB/8mpVBvWj2+Cx8ffWmMnenxUAVqEB/H2o89A2xPpW46ffRbFym5xDcmjFMX3eUpxYm8HqVybR6/Gv8/PS5BJ4gr3cgu5T09HRiYmJITU21O4rLCAgIoHLlyvj62vcfNrhMeXj4F05N7km9paNYm/kprbvqzUhuJ+MShz6/n8PRpelSdzjj72uOn4+33alUPvGoYhATE0NQUBDVq1fXKxrIuvY7ISGBmJgYwsPDbc0SXLYiXmN+IeHjnpxbNokZgTdzTysdUsRdmNSzxHwygBpJ66kXNop/3dccfy0EHsWjikFqaqoWAiciQpkyZYiPj7c7CgBBZSrh8/hSfvx+J7/O3k5ScjIPd9VLEV2dST7Bycm3U+HCAWZU/Df/GPUMPt56hNnTeNzfqP5i+StX+zyKBZdl0rD2DGoSQtsV97FiylM4dCwjl5WeeoGEiV0oeeEo39R8i8EPPKuFwEPp36oqdL7eXrw+sAWO0Hp0jPuCtZOGknYpze5Y6grn0zIYOWMnb6f05qdmn3LfkFF6H4EH02KQj5KSkvj444/tjuEWvHx8afrI10RVHkabpHnse6c7Z+Ljcl5QFYrE1V/x1qRJ/HHgNDf3G8ugfv1dbi9T5S8tBvnoasUgI0Mf+pId8fIiYtR/2dz8Neqk7WTX5PvYc+Kc3bGKNoeDuB/GEbJoLB2T5/P5/RH8o0WVnJdTbs+jTiA7e/mnnew6nr+/WOpXLMn42xtcdfq4ceM4ePAgTZs2xdfXl4CAAEJCQtizZw+LFi3itttuY8eOrAfIv/POO5w/f56XXnqJgwcP8sgjjxAfH0/x4sX57LPPqFu3br5md2XN7niEfZXq894vMez9eDX/HdSEbg0q2B2r6Ll0gZgvhlD55BLm+txK/RGfULtiabtTqULiscXADm+88QY7duxgy5YtLFu2jD59+rBjxw7Cw8M5cuTIVZcbPXo0n3zyCbVr12bdunWMGTOG33//vfCCu4Cbbu7Mx7VSeWDqBi7MHEFUjQbcPPRNxEsvXywMGSlJxE/qToWU/Uwr9RB3jH6FUiX87Y6lCpHHFoNrfYMvLC1btszx+v7z58+zevVqBg4c+GdbWlrRPJlaPjiAbx9owZbJJYk4+hk73ttFzQenUywoxO5oHi0p5RKPzdhDl+RwfOs8yD33jNArhoogjy0GrqBEiRJ/vvfx8cHh9PSvy3dJOxwOSpUqxZYtWwo7nksqViyA1k98w7Kv/0O7g+9x/P12yMBIqtRrZXc0z+NwEP3Lu/x7ayjrLpTjtn7vMKiF3ghYVGn5z0dBQUEkJydnOy0sLIxTp06RkJBAWloaP//8MwAlS5YkPDyc777LGtXTGMPWrVsLLbMrEi8vOt3/Aju7TaWY4zy+Mwfz/bpDuOuDmFyR43wCRz+6nSobJtDbsZTvH2qjhaCI0z2DfFSmTBnatm1Lw4YNKVasGGFhYX9O8/X15cUXX6Rly5ZUqlTpLyeIp0+fzsMPP8yECRNIT09n8ODBNGnSxI4uuJQm7e/gRM1mfPTjIv43ezcLd8fzeu+qlC2nJ5fzImHXCvhhBOUzEpkZ+hh9RrxIcHEddbSo86jHXu7evZt69erZlMh1ufvn4nAYvlx9hISFbzHcewFH2r1Li24D7I7ldowxrFn8PS1XjybWhLLjlg/ofWsvvX+giNHHXiq35eUljGwXzqC7h5HiXZIWq0aydNKDnDt/3u5obiMh+SJjpm9i2O++zCk+EDN6OX169tZCoP6kxUC5jWr1W1HxX2vYGnYnnRNmcvrd1qxduUjPJVyDcThYP+dDEt5txbrdR3iyZyP6P/0p1SvpoTb1V1oMlFvxDQikycNfcrD7lxQjjTcX7OL+yPUcOJX9ifui7NDuTWx+ozsttzxHhm8g3w5vwMOdauKt4wupbOgJZOWWara9k/QWfbhjw3HeW7yPZZMe5GjVqkQMfp7goEC749nq3IULHPhqDI1PzaOc+LO5/rM0uetZvLz1Bj51dbpnoNyWr58/w9uGs+yf7Wkdcp6usZNJejeClfO+JLMIDouddukSn688RId3/yDpxBHWl+1PxiObaPaP/9NCoHKkxUC5vTIli9Pwn/M40nMaPt7etN/0BIdfu5mVy38j0+H55xMupaWx8fu3SXy9PpHzV9KoUjDlHpxDm8ciKRVa0e54yk3oYSLlMaq37otp0ZtNCz4jZPNknv0llmJRy3mybVl6RtTFx8ez/rlfSElhw/xIauz6kJtNHNt9GjJxQB0iIvRubXX9POt/hwfKyMjwuF9iBUm8fWl++xgyez/EcztPMun3/QTPf5C4hWeIrX0v9Xo+RHDpsnbHzJMzFy7x9ap93LWmH52I55hPdba3nULDjgMRL93ZVzfGs3/LfNnn720N+kHLB+BSCkwf+PfpTe+BZvfChQT49v6/Ths+P8dN9uvXj+joaFJTUxk7diyjR48mMDCQBx54gEWLFlG+fHlmzpxJaGgonTp1okmTJixfvpyMjAwiIyNp2bLln8NaHzp0iKpVq/L6668zYsQITp8+TWhoKF9++SXBwcG0bNmSefPmUadOHe6++266dOnCAw88cGOflYfx9vaiT+MK9G4Yxo5FI7iw8TNa73ublL0TWVO6B6U6jqFuk1vc5jp743Cwc90ijm5cxJMnunMpw0GFiv1pevMt1L6lH2gRUHnk2cXABpGRkZQuXZqLFy/SokUL7rrrLi5cuEBERATvv/8+r7zyCi+//DIffvghACkpKWzZsoUVK1YwYsSIP593sGvXLlatWkWxYsW4/fbbGTp0KEOHDiUyMpLHH3+cOXPm8OGHHzJs2DDGjh1LYmKiFoJsiJcXjXqOhJ4jObhtFYnLPqZZwq+8+10Qq5Zn0r9+EL2qpFOlTgS4YGE4enAPMSv/R+Wjc2hoYqhOMUY07c+d7ZtyU1g2X3aUukGeXQyu9U3er/i1p5cok6s9gStNnDiR2bNnAxAdHc3+/fvx8vJi0KBBANx3333ceeedf85/9913A9ChQwfOnTtHUlISAHfccQfFihUDYM2aNfz4448ADBkyhGeeeQaA7t2789133/HII48U+cHtcqNm43bQuB3nzyZQa/sJ1m9NYufSWYz2+5g4CSMurCNlGnShatPOSFB5WzJmZDrYGn2GFfvPcG7zbManvEY1YI9vfTY2mED9bvczLjDYlmzKs7lMMRCRnsB/AW/gc2PMGzZHum7Lli3jt99+Y82aNRQvXpxOnTr9OVS1M+dDE1ceprj8s/Pw11fjcDjYvXs3xYsXJzExkcqVK+exB0VDYHAZBrUrw6B2cDKuCqtXlsX/4EIaxM0m4MS3sASerTaTGjVuon2JGGoFG/zK14PAcvm+95B6PoljO9eQdGA9HN9M+fO7mJPRi68dPehUuTFRFR+jWvv7qFut6Dz5TtnDJYqBiHgDHwHdgRhgg4jMM8bssjfZ9Tl79iwhISEUL16cPXv2sHbtWiDrl/b333/P4MGDmTFjBu3atftzmVmzZtG5c2dWrVpFcHAwwcF//9bXpk0bZs6cyZAhQ5g+fTrt27cH4P3336devXq89tprDB8+nDVr1uDr61s4nfUQYRWqEvaPp4CnOHPuPKvWLSPxwAbWxAcwa+8ewnw/pL73agBSvAJJKhHOxTINONPpdaqEFKd0+gn8ipeEYiFXLRSp6Zkknr/I6Zj9XIjeTmyK8EdmIw7EJfB94kBukkwATkgop4Pr07d+C/7ZvjshJfyAXoX0SaiiziWKAdASOGCMOQQgIjOBvoBbFYOePXvyySefUK9ePerUqUPr1q2BrG/569evZ8KECZQrV45Zs2b9uUxAQADNmjUjPT2dyMjIbNc7adIkhg8fzttvv/3nCeS9e/fy+eefs379eoKCgujQoQMTJkzg5ZdfLpS+eqLSJQPp1v026H4bA4H45DR27q3CzAObST2+i5LnD1Px7DEyk7Zz7541AMzye4VWXntwIFzCl3R82eVdh6f8XiA908HktH9Tl6NUkDQujwa00tGItcVepma5QFaEPEVIpVpUqn8LYRWqUN4Fz1uoosElhrAWkQFAT2PMKOvnIUArY8yjV8w3GhgNULVq1ZuPHj36l/W46lDNgYGBnM9mhM1OnTrxzjvvEBHxt9Fk85Wrfi7uKC0jk9jEixw7k0J04kWCYlYQeG4f3mlnMelpeGWmcdYvjOWhd+Pr5UXPpBmUIhnvgBL4hlQlsGpjQsMbExBYyu6uqCLqakNYu8qeQa4YY6YAUyDreQY2x1FFkL+PNzVCA6kRenn8oyHZztf3z3eNCyGVUnnnKsUgFqji9HNlq80jZLdXAFknnJVSyhW4yp0qG4DaIhIuIn7AYGDejazIFQ57uRL9PJRSueESxcAYkwE8CiwEdgPfGmN2Xu96AgICSEhI0F+AFmMMCQkJBAQE2B1FKeXiXOUwEcaYBcCCvKyjcuXKxMTEEB8fn0+p3F9AQIDef6CUypHLFIP84OvrS3h4uN0xlFLK7bjEYSKllFL20mKglFJKi4FSSikXuQP5RohIPHA0xxldU1ngtN0hCpH217Npf91LNWNM6JWNblsM3JmIRGV3O7in0v56Nu2vZ9DDREoppbQYKKWU0mJglyl2Byhk2l/Ppv31AHrOQCmllO4ZKKWU0mKglFIKLQYFSkTeFpE9IrJNRGaLSCmnaf8WkQMisldEbnVq72m1HRCRcbYEv0EiMlBEdoqIQ0Qirpjmcf29kif1xZmIRIrIKRHZ4dRWWkQWi8h+688Qq11EZKL1GWwTkeb2Jb9+IlJFRJaKyC7r3/JYq90j+/sXxhh9FdAL6AH4WO/fBN603tcHtgL+QDhwEPC2XgeBGoCfNU99u/txHf2tB9QBlgERTu0e2d8r+u4xfcmmbx2A5sAOp7a3gHHW+3FO/7Z7A78AArQG1tmd/zr7WgFobr0PAvZZ/349sr/OL90zKEDGmEUm61kNAGvJeoIbZD0VcaYxJs0Ycxg4ALS0XgeMMYeMMZeAmTg/QdHFGWN2G2P2ZjPJI/t7BU/qy18YY1YAZ65o7gtMtd5PBfo5tU8zWdYCpUSkQqEEzQfGmDhjzCbrfTJZz1ephIf215kWg8IzgqxvEJD1jyvaaVqM1Xa1dndXFPrrSX3JjTBjTJz1/gQQZr33mM9BRKoDzYB1FIH+etTzDOwgIr8B5bOZ9JwxZq41z3NABjC9MLMVhNz0VxUtxhgjIh51jbqIBAI/AE8YY86JyJ/TPLG/oMUgz4wx3a41XUSGAbcBXY11kBGIBao4zVbZauMa7S4hp/5ehdv29zpcq4+e6KSIVDDGxFmHRU5Z7W7/OYiIL1mFYLox5ker2WP7e5keJipAItITeAa4wxiT4jRpHjBYRPxFJByoDawHNgC1RSRcRPyAwda87q4o9NeT+pIb84Ch1vuhwFyn9vutq2xaA2edDq+4PMnaBfgC2G2Mec9pkkf29y/sPoPtyS+yTpRGA1us1ydO054j6+qTvUAvp/beZF3BcJCsQy+29+M6+tufrGOmacBJYKEn9zeb/ntMX67o1zdAHJBu/f2OBMoAS4D9wG9AaWteAT6yPoPtOF1V5g4voB1ggG1O/297e2p/nV86HIVSSik9TKSUUkqLgVJKKbQYKKWUQouBUkoptBgopZRCi4FSSim0GCillAL+H5VKrq41TpKxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: > target: 100.0\n",
      "x_adv: [-128.761  -161.6738 -132.4278 -110.3967   94.7062]\n",
      "6631.738230623121\n",
      "10455.580507299925\n",
      "7014.831078929342\n",
      "4875.221403183651\n",
      "3588.046596067835\n",
      "op: < target: 100.0\n",
      "x_adv: [2.9609 2.9609 2.9609 2.9596 2.9609]\n",
      "3.7859697133827868\n",
      "3.7857436732443444\n",
      "3.786195835636982\n",
      "3.7761029207355326\n",
      "3.7859697133827868\n",
      "op: == target: 100.0\n",
      "x_adv: [-12.4349  15.7057  15.7055 -12.4348 -12.4348]\n",
      "62.374847593641114\n",
      "98.92737171534905\n",
      "98.92609600469517\n",
      "62.37389948398982\n",
      "62.37389948398982\n"
     ]
    }
   ],
   "source": [
    "phase4_start = time.time()\n",
    "\n",
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)\n",
    "    \n",
    "phase4_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 50.0\n",
      "Total Runtime: 6.834798574447632\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "\n",
    "total_time = phase1_end - phase1_start + \\\n",
    "             phase2_end - phase2_start + \\\n",
    "             phase3_end - phase3_start + \\\n",
    "             phase4_end - phase4_start\n",
    "\n",
    "print(\"Total Runtime:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
