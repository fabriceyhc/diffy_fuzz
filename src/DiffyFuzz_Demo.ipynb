{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_textbook_fn(x):\n",
    "    return (0.2) + \\\n",
    "           (0.4 * x**2) + \\\n",
    "           (0.3 * np.sin(15 * x)) + \\\n",
    "           (0.05 * np.cos(50 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "    print(y)\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if y > 100:\n",
    "        return \"dl_textbook_fn returned a value more than 100!\"\n",
    "    elif y < 100:\n",
    "        return \"dl_textbook_fn returned a value less than 100!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[5, 0], [5, 1], [8, 0], [8, 1], [10, 0], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "phase1_start = time.time()\n",
    "\n",
    "config = get_subject_programs_config()[6]\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')\n",
    "    \n",
    "phase1_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase2_start = time.time()\n",
    "\n",
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)\n",
    "\n",
    "phase2_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '==', 'target': '100'},\n",
       "   {'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'}],\n",
       "  'target_fn': <function __main__.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd92764ba934b16ac25e1a3aafc7e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c08f05f2018462aa60d6afe81c84cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0033822718542069197}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "phase3_start = time.time()\n",
    "\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    input_range = (-50, 50), \n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 1000, \n",
    "    batch_size=10, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./logs/\", name=fn.__name__)\n",
    "escb = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=2, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=torch.cuda.device_count(),\n",
    "    logger=tb_logger,\n",
    "    callbacks=[escb]\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "phase3_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: == target: 100.0\n",
      "x_adv: [ 15.8348 -15.9673  15.8348 -15.9671 -15.9672]\n",
      "100.26263882365998\n",
      "error You found a hard-to-reach bug!\n",
      "102.02340542560876\n",
      "100.26263882365998\n",
      "error You found a hard-to-reach bug!\n",
      "102.0221718699339\n",
      "102.02285375027637\n",
      "op: > target: 100.0\n",
      "x_adv: [ 50. -50.  50. -50.  50.]\n",
      "1000.4615131407621\n",
      "1000.0144693705869\n",
      "1000.4615131407621\n",
      "1000.0144693705869\n",
      "1000.4615131407621\n",
      "op: < target: 100.0\n",
      "x_adv: [0.2942 0.2942 0.2941 0.2941 0.2943]\n",
      "-0.0790884925743124\n",
      "-0.07912504414655647\n",
      "-0.07874650590944596\n",
      "-0.07867302633745246\n",
      "-0.07958651987577367\n"
     ]
    }
   ],
   "source": [
    "phase4_start = time.time()\n",
    "\n",
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)\n",
    "    \n",
    "phase4_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 83.33\n",
      "Total Runtime: 3.9104599952697754\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "\n",
    "total_time = phase1_end - phase1_start + \\\n",
    "             phase2_end - phase2_start + \\\n",
    "             phase3_end - phase3_start + \\\n",
    "             phase4_end - phase4_start\n",
    "\n",
    "print(\"Total Runtime:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
