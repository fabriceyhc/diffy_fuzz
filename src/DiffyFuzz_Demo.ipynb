{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_textbook_fn(x):\n",
    "    return (0.2) + \\\n",
    "           (0.4 * x**2) + \\\n",
    "           (0.3 * np.sin(15 * x)) + \\\n",
    "           (0.05 * np.cos(50 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "    print(y)\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if y > 100:\n",
    "        return \"dl_textbook_fn returned a value more than 100!\"\n",
    "    \n",
    "    if y < 100:\n",
    "        return \"dl_textbook_fn returned a value less than 100!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fn(x):\n",
    "    return 20*x + 3*x**2 + 0.1*x**3\n",
    "\n",
    "def program_4_sym(x: float):\n",
    "    y:float = 20*x + 3*x**2 + 0.1*x**3\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if y == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "        \n",
    "    return r\n",
    "\n",
    "def program_4(x: float):\n",
    "    y:float = poly_fn(x)\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if round(y, 2) == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "76qmzmqjJAiL"
   },
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "\n",
    "    if y > 0:\n",
    "        print(\"dl_textbook_fn returned a positive value!\")\n",
    "    elif y < 0:\n",
    "        print(\"dl_textbook_fn returned a negative value!\")\n",
    "    elif y == 0:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.505904007381"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_textbook_fn(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[4, 0], [4, 1], [6, 0], [6, 1], [9, 0], [9, 1]]\n"
     ]
    }
   ],
   "source": [
    "phase1_start = time.time()\n",
    "\n",
    "config = get_subject_programs_config()[6]\n",
    "# print(config)\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_total_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_total_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')\n",
    "    \n",
    "phase1_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase2_start = time.time()\n",
    "\n",
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)\n",
    "\n",
    "phase2_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'},\n",
       "   {'operator': '==', 'target': '100'}],\n",
       "  'target_fn': <function __main__.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "/home/apoorvg/Documents/py-3.9.7/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 225/225 [00:01<00:00, 183.69it/s, loss=0.00255, v_num=229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apoorvg/Documents/py-3.9.7/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.00224548508413136}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 25/25 [00:00<00:00, 806.32it/s]\n"
     ]
    }
   ],
   "source": [
    "phase3_start = time.time()\n",
    "\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    input_range = (-50, 50), \n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 1000, \n",
    "    batch_size=4, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=torch.cuda.device_count()\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "phase3_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: > target: 100.0\n",
      "x_adv: [-50.     -50.      50.      32.8153 -50.    ]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "coming here program_7\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "op: < target: 100.0\n",
      "x_adv: [-0.3498 -0.3498 -0.3498 -0.3497 -0.3498]\n",
      "dl_textbook_fn returned a value less than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [6, 'program_7', 'line'], [7, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "coming here program_7\n",
      "dl_textbook_fn returned a value less than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [6, 'program_7', 'line'], [7, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value less than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [6, 'program_7', 'line'], [7, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value less than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [6, 'program_7', 'line'], [7, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value less than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [6, 'program_7', 'line'], [7, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "op: == target: 100.0\n",
      "x_adv: [-15.7878  15.8916 -15.7878  15.8916 -15.7877]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "error ('You found a hard-to-reach bug!', 100.14832675636471)\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line'], [10, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "coming here program_7\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "error ('You found a hard-to-reach bug!', 100.14832675636471)\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line'], [10, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "None Dwdw\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line']]\n",
      "[4, 6, 9]\n",
      "dl_textbook_fn returned a value more than 100!\n",
      "error ('You found a hard-to-reach bug!', 100.14635548980819)\n",
      "[[2, 'program_7', 'line'], [4, 'program_7', 'line'], [5, 'program_7', 'line'], [6, 'program_7', 'line'], [9, 'program_7', 'line'], [10, 'program_7', 'line']]\n",
      "[4, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "phase4_start = time.time()\n",
    "\n",
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)\n",
    "    \n",
    "phase4_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 100.0\n",
      "Total Runtime: 3.3209452629089355\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "\n",
    "total_time = phase1_end - phase1_start + \\\n",
    "             phase2_end - phase2_start + \\\n",
    "             phase3_end - phase3_start + \\\n",
    "             phase4_end - phase4_start\n",
    "\n",
    "print(\"Total Runtime:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "interpreter": {
   "hash": "1b8ded426d52afcc87343e9d52eaf8df39111ab2058820fcbfefc966893bd7f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
