{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_textbook_fn(x):\n",
    "    return (0.2) + \\\n",
    "           (0.4 * x**2) + \\\n",
    "           (0.3 * np.sin(15 * x)) + \\\n",
    "           (0.05 * np.cos(50 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "    print(y)\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if y > 100:\n",
    "        return \"dl_textbook_fn returned a value more than 100!\"\n",
    "    elif y < 100:\n",
    "        return \"dl_textbook_fn returned a value less than 100!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fn(x):\n",
    "    return 20*x + 3*x**2 + 0.1*x**3\n",
    "\n",
    "def program_4_sym(x: float):\n",
    "    y:float = 20*x + 3*x**2 + 0.1*x**3\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if y == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "        \n",
    "    return r\n",
    "\n",
    "def program_4(x: float):\n",
    "    y:float = poly_fn(x)\n",
    "    r:float = 0.0\n",
    "    if y > 0:\n",
    "        r = 1.75\n",
    "    elif y < 0:\n",
    "        r = 0.633\n",
    "    elif y == 0:\n",
    "        r = 322.22\n",
    "\n",
    "    if round(y, 2) == 10.75:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "76qmzmqjJAiL"
   },
   "outputs": [],
   "source": [
    "def program_7(x: float):\n",
    "    y:float = dl_textbook_fn(x)\n",
    "\n",
    "    if y > 0:\n",
    "        print(\"dl_textbook_fn returned a positive value!\")\n",
    "    elif y < 0:\n",
    "        print(\"dl_textbook_fn returned a negative value!\")\n",
    "    elif y == 0:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")\n",
    "\n",
    "    if round(y, 0) == 100:\n",
    "        raise Exception(\"You found a hard-to-reach bug!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000.505904007381"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_textbook_fn(-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[5, 0], [5, 1], [8, 0], [8, 1], [10, 0], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "phase1_start = time.time()\n",
    "\n",
    "config = get_subject_programs_config()[6]\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')\n",
    "    \n",
    "phase1_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phase2_start = time.time()\n",
    "\n",
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)\n",
    "\n",
    "phase2_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '==', 'target': '100'},\n",
       "   {'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'}],\n",
       "  'target_fn': <function __main__.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6522a6fe1542482aa33bd94bd4f2f921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b805db9b0945c4b533661e062dd836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.001828295411542058}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "phase3_start = time.time()\n",
    "\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    input_range = (-50, 50), \n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 1000, \n",
    "    batch_size=4, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=3,\n",
    "    gpus=torch.cuda.device_count()\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "phase3_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: == target: 100.0\n",
      "x_adv: [-15.8086  15.7613 -15.8086  15.7613  15.7613]\n",
      "100.48006935701277\n",
      "error You found a hard-to-reach bug!\n",
      "99.3081176944576\n",
      "100.4792523929514\n",
      "error You found a hard-to-reach bug!\n",
      "99.30741847082253\n",
      "99.30767260325442\n",
      "op: > target: 100.0\n",
      "x_adv: [ 50.  50. -50.  50. -50.]\n",
      "1000.4615131407621\n",
      "1000.4615131407621\n",
      "1000.0144693705869\n",
      "1000.4615131407621\n",
      "1000.0144693705869\n",
      "op: < target: 100.0\n",
      "x_adv: [0.0258 0.0257 0.0258 0.0259 0.0258]\n",
      "0.3273096741399263\n",
      "0.3270979391525598\n",
      "0.3273301203917536\n",
      "0.3274730269013223\n",
      "0.327323305838657\n"
     ]
    }
   ],
   "source": [
    "phase4_start = time.time()\n",
    "\n",
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)\n",
    "    \n",
    "phase4_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 83.33\n",
      "Total Runtime: 12.512135744094849\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "\n",
    "total_time = phase1_end - phase1_start + \\\n",
    "             phase2_end - phase2_start + \\\n",
    "             phase3_end - phase3_start + \\\n",
    "             phase4_end - phase4_start\n",
    "\n",
    "print(\"Total Runtime:\", total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
