{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2qxf47_IwAy"
   },
   "source": [
    "# DiffyFuzz\n",
    "\n",
    "`DiffyFuzz` is a novel testing tool that approximates program logic differentiably so that inputs can be crafted to access tricky branches.\n",
    "\n",
    "This tool can be used directly or incorporated as an extension to other techniques, like symbolic and concolic execution. When the base tool can no longer improve coverage statistics, DiffyFuzz activates to expand coverage for numerically guarded branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBS5zOh6I5Ik"
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from legend import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TlsQDR3-68dD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from target_programs.functions_to_approximate import *\n",
    "from SymbolicFuzzer import SimpleSymbolicFuzzer\n",
    "\n",
    "import ast\n",
    "import astor\n",
    "import time\n",
    "import inspect\n",
    "import itertools\n",
    "from collections import deque\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pyfuzz\n",
    "\n",
    "from cleverhans.torch.utils import clip_eta\n",
    "from cleverhans.torch.utils import optimize_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfyQxVVyKgc9"
   },
   "source": [
    "## Subject Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuzz_fn(x):\n",
    "    z = math.pow(3, x)\n",
    "    if z < 1:\n",
    "        return 0\n",
    "    elif z < 1e3:\n",
    "        return 1\n",
    "    elif z < 1e6:\n",
    "        return 2\n",
    "    elif z > 1e6:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def program_11_sym(x: int):\n",
    "    z:int = 3**x\n",
    "    y:int = 0\n",
    "    if z < 1:\n",
    "        y = 0\n",
    "    elif z < 1e3:\n",
    "        y = 1\n",
    "    elif z < 1e6:\n",
    "        y = 2\n",
    "    elif z > 1e6:\n",
    "        y = 3\n",
    "    r:float = 0.0\n",
    "    if y == 0:\n",
    "        r = 'Got 0'\n",
    "    elif y == 1:\n",
    "        r = 'Got 1'\n",
    "    elif y == 2:\n",
    "        r = 'Got 2'\n",
    "    elif y == 3:\n",
    "        r = 'Got 3'\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3Ia1Ga3I_m4"
   },
   "source": [
    "## Phase 1\n",
    "Run a baseline test generation routine to initialize a coverage profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufCv2I3nJZc2"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "AOuACHEDJc6F"
   },
   "outputs": [],
   "source": [
    "# class SimpleSymbolicFuzzer(Fuzzer):\n",
    "#     \"\"\"Simple symbolic fuzzer\"\"\"\n",
    "#     ...\n",
    "#     Too much to display here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LnVIzNNJdgw"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_subject_programs_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cbUdOqAkJhF3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 0.0\n",
      "Uncovered Branches: [[5, 0], [5, 1], [7, 0], [7, 1], [10, 0], [10, 1]]\n"
     ]
    }
   ],
   "source": [
    "config = configs[6]\n",
    "\n",
    "results = []\n",
    "\n",
    "symbolic_execution = config['symbolic']\n",
    "symbolic_target_program = config['symbolic_target_program']\n",
    "target_program = config['target_program']\n",
    "precision = config['precision']\n",
    "external_func_length = config['external_func_length']\n",
    "\n",
    "symfz_ct = SimpleSymbolicFuzzer(\n",
    "    symbolic_target_program, \n",
    "    precision = precision, \n",
    "    external_func_length = external_func_length\n",
    ")\n",
    "\n",
    "#check if symbolic execution can be performed\n",
    "if symbolic_execution:\n",
    "    symfz_ct.start_execution(tries=100)\n",
    "else:\n",
    "    symfz_ct.collect_branch_conditions()\n",
    "\n",
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())\n",
    "print(\"Uncovered Branches:\", symfz_ct.branches_uncovered)\n",
    "\n",
    "results.append(target_program.__name__)\n",
    "results.append(str(symfz_ct.calculate_branch_coverage())+'%')\n",
    "results.append(str(symfz_ct.execution_time)+\" sec\")\n",
    "\n",
    "if(len(symfz_ct.branches_uncovered) == 0):\n",
    "    results.append('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80cZo2FbJKXQ"
   },
   "source": [
    "## Phase 2\n",
    "\n",
    "Identify blocking code logic that inhibits branch exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XofdJ0fFJiww"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Z7Yy6NauJkjn"
   },
   "outputs": [],
   "source": [
    "class FunctionAndBranchConditionsExtractor():\n",
    "    \"\"\"Extract function for dataset generation and condition components\"\"\"\n",
    "\n",
    "    def __init__(self, sub_program):\n",
    "        self.var_map = {}\n",
    "        self.sub_program = sub_program\n",
    "\n",
    "    def collectVariables(self, tree):\n",
    "        \"\"\"Explores the AST and stores function assignment in a dictionary\"\"\"\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.AnnAssign):\n",
    "                self.var_map[node.target.id] = node\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return self.var_map\n",
    "\n",
    "    def extractVariables(self, tree):\n",
    "        \"\"\"Explores the AST and returns the function name used for variable assignment\"\"\"\n",
    "        variables = []\n",
    "        \n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.Name):\n",
    "                if node.id in self.var_map:\n",
    "                    variables.append(astor.to_source(self.var_map[node.id].value).strip())\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return variables[0]\n",
    "\n",
    "    def collect_conditionComponents(self, tree):\n",
    "        \"\"\"Explores the AST and extracts branch conditions and target function\"\"\"\n",
    "        conditionComponents = []\n",
    "        self.collectVariables(tree)\n",
    "        \"\"\"Extract uncovered branches\"\"\"\n",
    "        branches = [b for b, _ in self.sub_program.branches_uncovered]\n",
    "\n",
    "        def traverse(node):\n",
    "            if isinstance(node, ast.If):\n",
    "                if node.lineno in branches:\n",
    "                    conditionComponentsDict = {}\n",
    "                    conditionComponentsDict[\"target_fn\"] = self.extractVariables(node.test)\n",
    "                    processed_branchConditions = self.process_branchConditions(astor.to_source(node.test).strip())\n",
    "                    conditionComponentsDict[\"branch_conditions\"] = [{}]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"operator\"] = processed_branchConditions[0]\n",
    "                    conditionComponentsDict[\"branch_conditions\"][0][\"target\"] = processed_branchConditions[1]\n",
    "                    conditionComponents.append(conditionComponentsDict)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                traverse(child)\n",
    "        traverse(tree)\n",
    "        return conditionComponents\n",
    "\n",
    "    def process_branchConditions(self, branchCondition):\n",
    "        \"Extract operand and target from branch conditions\"\n",
    "        branchCondition = branchCondition[1:-1]\n",
    "        branchConditionArray = []\n",
    "        branchConditionArray = branchCondition.split()\n",
    "        branchConditionArrayUpdated = [branchConditionArray[len(branchConditionArray) - 2], branchConditionArray[len(branchConditionArray) - 1]]\n",
    "        return branchConditionArrayUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbYN2LSUJlSz"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "n3pEaA4iJncd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "source_ast = ast.parse(inspect.getsource(target_program))\n",
    "\n",
    "funCondExtractor = FunctionAndBranchConditionsExtractor(symfz_ct)\n",
    "\n",
    "\"\"\"Pass the function ast to extract branch conditions and target function\"\"\"\n",
    "funCondExtractor.collect_conditionComponents(source_ast)\n",
    "\n",
    "conditionComponents = funCondExtractor.collect_conditionComponents(source_ast)\n",
    "# print(conditionComponents)\n",
    "# sys.exit(0)\n",
    "\n",
    "\"Process the condition components to obtain the function in memory and extract operands and target from branch conditions\"\n",
    "processed_conditionComponentsArray = []\n",
    "processed_conditionComponentsDict = {}\n",
    "processed_conditionComponentsDict[\"branch_conditions\"] = []\n",
    "\n",
    "target = conditionComponents[0][\"target_fn\"]\n",
    "targetNew = \"\"\n",
    "\n",
    "for char in target:\n",
    "    if char != \"(\":\n",
    "        targetNew += char\n",
    "    elif char == \"(\":\n",
    "        break \n",
    "# print(locals())\n",
    "processed_conditionComponentsDict[\"target_fn\"] = eval(targetNew)\n",
    "\n",
    "for idx in range(len(conditionComponents)):\n",
    "    processed_conditionComponentsDict[\"branch_conditions\"].append(conditionComponents[idx][\"branch_conditions\"][0])\n",
    "\n",
    "processed_conditionComponentsArray.append(processed_conditionComponentsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'branch_conditions': [{'operator': '>', 'target': '100'},\n",
       "   {'operator': '<', 'target': '100'},\n",
       "   {'operator': '==', 'target': '100'}],\n",
       "  'target_fn': <function target_programs.functions_to_approximate.dl_textbook_fn(x)>}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_conditionComponentsArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-w5Z9KBTJSxD"
   },
   "source": [
    "## Phase 3\n",
    "Approximate target function with a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH5z6AAIJqWc"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfT0JphKHL6"
   },
   "source": [
    "#### Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "2y9gywNmKJ5H"
   },
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    def __init__(self, fn):\n",
    "      \n",
    "        self.fn = fn\n",
    "\n",
    "        # extract fn argument details\n",
    "        argspecs = inspect.getfullargspec(self.fn)\n",
    "        self.args = argspecs.args\n",
    "        self.defaults = argspecs.defaults\n",
    "\n",
    "        self.num_inputs = len(self.args)\n",
    "        self.num_outputs = inspect.getsource(self.fn).split().count(\"return\")\n",
    "\n",
    "    @staticmethod\n",
    "    def fuzz_inputs(num_inputs = 1000, \n",
    "                    input_range = (-255, 255), \n",
    "                    seed = None):\n",
    "        if not seed:\n",
    "            seed = [bytearray(range(10))]\n",
    "        fuzzer = pyfuzz.MutationFuzzer(seed, mutator=pyfuzz.mutate_bytes)\n",
    "        input_bytes = [fuzzer.fuzz() for _ in range(num_inputs)]\n",
    "        inputs = []\n",
    "        for in_ in input_bytes:\n",
    "            fdi = pyfuzz.FuzzedDataInterpreter(in_)\n",
    "            inputs.append(fdi.claim_float_in_range(input_range[0], input_range[1]))\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, \n",
    "                 input_range = (-255, 255), \n",
    "                 num_examples_per_arg = 1000,\n",
    "                 scaler = None,\n",
    "                 train_test_split = 0.9,\n",
    "                 batch_size = 10,\n",
    "                 max_dataset_size = 10000,\n",
    "                 fuzz_generate = True):\n",
    "      \n",
    "        inputs = {}\n",
    "        for a in self.args:\n",
    "\n",
    "            if fuzz_generate:\n",
    "                inputs[a] = self.fuzz_inputs(num_inputs=num_examples_per_arg, \n",
    "                                            input_range=input_range)\n",
    "            else:\n",
    "                inputs[a] = np.linspace(start=input_range[0], \n",
    "                                        stop=input_range[1], \n",
    "                                        num=num_examples_per_arg)\n",
    "\n",
    "        X = torch.Tensor(list(itertools.product(*inputs.values())))\n",
    "\n",
    "        # enforce dataset size limit\n",
    "        if len(X) > max_dataset_size:\n",
    "            idx = torch.randperm(len(X))\n",
    "            X = X[idx]\n",
    "            X = X[:max_dataset_size]\n",
    "\n",
    "        y = torch.Tensor([self.fn(*x) for x in X])\n",
    "\n",
    "        # filter out inf\n",
    "        X = X[~torch.isinf(y)]\n",
    "        y = y[~torch.isinf(y)]\n",
    "\n",
    "        # scale dataset if provided\n",
    "        if scaler:\n",
    "            self.x_scaler = scaler()\n",
    "            self.y_scaler = scaler()\n",
    "\n",
    "            self.x_scaler.fit(X)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "            X = self.x_scaler.transform(X)\n",
    "            y = self.y_scaler.transform(y)\n",
    "            \n",
    "        if self.num_outputs == 1:\n",
    "            y = y.float().reshape(-1, 1)\n",
    "        else:\n",
    "            y = torch.flatten(y.long())\n",
    "\n",
    "        full_dataset = TensorDataset(X, y)\n",
    "\n",
    "        # split dataset for train & test\n",
    "        train_size = int(train_test_split * len(full_dataset))\n",
    "        test_size = len(full_dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "        # package as dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq3pVPzLKE6e"
   },
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "81JdD47BJptV"
   },
   "outputs": [],
   "source": [
    "class FuncApproximator(LightningModule):\n",
    "    def __init__(self, input_size=1, output_size=1):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        super(FuncApproximator, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, output_size),\n",
    "        )\n",
    "        if output_size == 1:\n",
    "            self.loss_fn = F.l1_loss # F.mse_loss F.l1_loss\n",
    "        else:\n",
    "            self.loss_fn = F.cross_entropy\n",
    "            self.accuracy = torchmetrics.Accuracy()\n",
    "            self.accuracy.mode = \"multi-class\"\n",
    "\n",
    "        # set after training\n",
    "        self.x_scaler = None\n",
    "        self.y_scaler = None\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.linear_relu_stack(x)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        train_loss = self.loss_fn(out, y)\n",
    "\n",
    "        # log step metric\n",
    "        self.log(\"train_loss\", train_loss)\n",
    "\n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('train_acc', self.accuracy)\n",
    "\n",
    "        return train_loss\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        if self.output_size > 1:\n",
    "            self.log('train_acc_epoch', self.accuracy)\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):\n",
    "    #     x, y = batch\n",
    "    #     out = self(x)\n",
    "        \n",
    "    #     # log step metric\n",
    "    #     val_loss = self.loss_fn(out, y)\n",
    "    #     self.log(\"val_loss\", val_loss)\n",
    "        \n",
    "    #     if self.output_size > 1:\n",
    "    #         self.accuracy(out, y)\n",
    "    #         self.log('val_acc', self.accuracy)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        out = self(x)\n",
    "        test_loss = self.loss_fn(out, y)\n",
    "        \n",
    "        # log step metric\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "        if self.output_size > 1:\n",
    "            self.accuracy(out, y)\n",
    "            self.log('test_acc', self.accuracy)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        y_pred = self(x)\n",
    "        if self.y_scaler and self.output_size == 1:\n",
    "            y_pred = self.y_scaler.inverse_transform(y_pred)\n",
    "        return y_pred\n",
    "        \n",
    "\n",
    "class MinMaxScaler(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "    Transforms each channel to the range [a, b].\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        if not 'feature_range' in kwargs:\n",
    "            self.feature_range = [0, 1]\n",
    "\n",
    "    def fit(self, tensor):\n",
    "        self.min_ = tensor.min(dim=0, keepdim=True)[0]\n",
    "        self.max_ = tensor.max(dim=0, keepdim=True)[0]\n",
    "        dist = self.max_ - self.min_\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        self.scale_ = 1.0 / dist\n",
    "        return self\n",
    "\n",
    "    def transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        a, b = self.feature_range\n",
    "        tensor = (tensor - self.min_) * self.scale_\n",
    "        tensor = tensor * (b - a) + a\n",
    "        return tensor\n",
    "\n",
    "    def inverse_transform(self, tensor):\n",
    "        tensor = torch.clone(tensor)\n",
    "        tensor /= self.scale_\n",
    "        tensor += self.min_\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyA41ApJJsqm"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "067GsuEnJuXS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name              | Type       | Params\n",
      "-------------------------------------------------\n",
      "0 | flatten           | Flatten    | 0     \n",
      "1 | linear_relu_stack | Sequential | 264 K \n",
      "-------------------------------------------------\n",
      "264 K     Trainable params\n",
      "0         Non-trainable params\n",
      "264 K     Total params\n",
      "1.057     Total estimated model params size (MB)\n",
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4618add2a644c986e431fdbb7000a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabriceyhc\\anaconda3\\envs\\pyfuzz\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713a3e68dfa948b2aba34c49e8c6aa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': 0.0004963481915183365}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# show dataset + training\n",
    "fn = processed_conditionComponentsArray[0]['target_fn']\n",
    "\n",
    "dg = DatasetGenerator(fn)\n",
    "\n",
    "train_loader, test_loader = dg(\n",
    "    scaler=MinMaxScaler, \n",
    "    num_examples_per_arg = 10000, \n",
    "    max_dataset_size = 10000, \n",
    "    batch_size=10, \n",
    "    fuzz_generate=False)\n",
    "\n",
    "model = FuncApproximator(\n",
    "    input_size=dg.num_inputs,\n",
    "    output_size=dg.num_outputs)\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"./logs/\", name=fn.__name__)\n",
    "escb = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=2, verbose=False, mode=\"min\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5,\n",
    "    gpus=torch.cuda.device_count(),\n",
    "    logger=tb_logger,\n",
    "    callbacks=[escb]\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "if 'x_scaler' in dg.__dict__:\n",
    "    model.x_scaler = dg.x_scaler\n",
    "if 'y_scaler' in dg.__dict__:\n",
    "    model.y_scaler = dg.y_scaler\n",
    "\n",
    "## Include plots showing function fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model.output_size == 1:\n",
    "    x, y_true = test_loader.dataset[:]\n",
    "    x = model.x_scaler.inverse_transform(x)\n",
    "    y_true = model.y_scaler.inverse_transform(y_true)\n",
    "    y_pred = model.predict(x)\n",
    "\n",
    "    sns.lineplot(x=x.view(-1), y=y_true.view(-1), label = 'true')\n",
    "    sns.lineplot(x=x.view(-1), y=y_pred.view(-1).detach(), linestyle='--', label = 'approx')\n",
    "    plt.title(fn.__name__)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whqa0K8rJXH7"
   },
   "source": [
    "## Phase 4\n",
    "Generate new tests via gradient-guided mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWDw2qC3Ju62"
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "cOuw8F9kJwfR"
   },
   "outputs": [],
   "source": [
    "class GradientInputGenerator:\n",
    "    def __init__(self, \n",
    "                 eps=1., \n",
    "                 eps_iter=0.1, \n",
    "                 nb_iter=1000, \n",
    "                 norm=2,\n",
    "                 target_scaler=255,\n",
    "                 num_seeds=1):\n",
    "      \n",
    "        self.eps = eps\n",
    "        self.eps_iter = eps_iter\n",
    "        self.nb_iter = nb_iter\n",
    "        self.norm = norm\n",
    "        self.target_scaler = target_scaler\n",
    "        self.num_seeds = num_seeds\n",
    "\n",
    "    def __call__(self, \n",
    "                 model,\n",
    "                 op,\n",
    "                 target,\n",
    "                 seed=None):\n",
    "      \n",
    "        if not seed:\n",
    "            # create default seed at midpoint in input space [0,1]\n",
    "            seed = torch.rand((self.num_seeds, model.input_size))\n",
    "        else:\n",
    "            # scale provided input seed for model\n",
    "            seed = model.x_scaler.transform(seed)\n",
    "\n",
    "        # set target op for pgd\n",
    "        if op == \">\" or op == \">=\":\n",
    "            # make larger\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * self.target_scaler\n",
    "        elif op == \"<\" or op == \"<=\":\n",
    "            # make smaller\n",
    "            target = 1. if target == 0 else target\n",
    "            target = target * -self.target_scaler\n",
    "        elif op == \"==\":\n",
    "            # equal the target value\n",
    "            target = target\n",
    "        else:\n",
    "            raise ValueError(\"Unhandled op!\")\n",
    "\n",
    "        target = torch.full((self.num_seeds, 1), target) \n",
    "\n",
    "        # loss function + target transform based on model output \n",
    "        if model.output_size == 1:\n",
    "            loss_fn = F.l1_loss  \n",
    "            if op != \"==\":\n",
    "                target *= torch.rand_like(target)\n",
    "            target  = model.y_scaler.transform(target)\n",
    "        else:\n",
    "            loss_fn = F.cross_entropy\n",
    "            target  = target.reshape(-1).long()\n",
    " \n",
    "        # generate input via pgd\n",
    "        x_adv = projected_gradient_descent(\n",
    "            model_fn=model,\n",
    "            x=seed,\n",
    "            y=target,\n",
    "            targeted=True,\n",
    "            loss_fn=loss_fn,\n",
    "            eps=self.eps,\n",
    "            eps_iter=self.eps_iter, \n",
    "            nb_iter=self.nb_iter,\n",
    "            norm=self.norm,\n",
    "            clip_min=0,\n",
    "            clip_max=1,\n",
    "            rand_init=True,\n",
    "            rand_minmax=None,\n",
    "            sanity_checks=False,\n",
    "            early_stopping=True\n",
    "        ).detach()\n",
    "\n",
    "        x_adv = model.x_scaler.inverse_transform(x_adv)\n",
    "\n",
    "        return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noYcn9QaJw2k"
   },
   "source": [
    "### Phase Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "DS3_TaQLKaIB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op: > target: 100.0\n",
      "x_adv: [205.705  107.2395 117.5865 -94.7215  96.3122]\n",
      "16926.210687876137\n",
      "4600.318624872275\n",
      "5530.527960500159\n",
      "3588.8533712032136\n",
      "3710.4377157127547\n",
      "op: < target: 100.0\n",
      "x_adv: [6.3976 6.3975 6.3975 6.3976 6.397 ]\n",
      "16.910569498218326\n",
      "16.910214730290537\n",
      "16.910214730290537\n",
      "16.910569498218326\n",
      "16.90717349995497\n",
      "op: == target: 100.0\n",
      "x_adv: [-16.3803 -16.3804 -16.3791 -16.3795 -16.3803]\n",
      "107.31253528837847\n",
      "107.31276528731637\n",
      "107.30342220079395\n",
      "107.30625210797379\n",
      "107.31253528837847\n"
     ]
    }
   ],
   "source": [
    "op_targets = []\n",
    "for cond in processed_conditionComponentsArray[0]['branch_conditions']:\n",
    "    op_targets.append((cond['operator'], float(cond['target'])))\n",
    "\n",
    "generator = GradientInputGenerator(num_seeds=5)\n",
    "\n",
    "for op, target in op_targets:\n",
    "    x_adv = generator(model=model, op=op, target=target).numpy()\n",
    "    \n",
    "    print(\"op:\", op, 'target:', target)\n",
    "    print('x_adv:', x_adv.reshape(-1))\n",
    "    symfz_ct.collect_additional_covergae(x_adv, model.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "-tZNPZMmL4rw"
   },
   "outputs": [],
   "source": [
    "# show before and after coverage changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Branch Cov (%): 66.67\n"
     ]
    }
   ],
   "source": [
    "print(\"Branch Cov (%):\", symfz_ct.calculate_branch_coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lBS5zOh6I5Ik",
    "8LnVIzNNJdgw",
    "80cZo2FbJKXQ",
    "XofdJ0fFJiww",
    "BbYN2LSUJlSz",
    "-w5Z9KBTJSxD",
    "mH5z6AAIJqWc",
    "nyA41ApJJsqm",
    "whqa0K8rJXH7",
    "kWDw2qC3Ju62"
   ],
   "name": "DiffyFuzz Demo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
